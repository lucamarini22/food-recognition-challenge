{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the pycoco library\n!pip install pycocotools","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":14.682415,"end_time":"2021-05-10T15:30:37.398733","exception":false,"start_time":"2021-05-10T15:30:22.716318","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport imgaug.augmenters as iaa","metadata":{"papermill":{"duration":2.275126,"end_time":"2021-05-10T15:30:39.69131","exception":false,"start_time":"2021-05-10T15:30:37.416184","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set important parameters\nIMAGE_SIZE = (48, 48)\nBATCH_SIZE = 300\nEPOCHS = 10","metadata":{"papermill":{"duration":0.024203,"end_time":"2021-05-10T15:30:39.732233","exception":false,"start_time":"2021-05-10T15:30:39.70803","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the image and annotation paths\ntrain_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\ntrain_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n\nval_imgs_path = '../input/food-recognition-challenge/val-v0.4/val/images'\nval_anns_path = '../input/food-recognition-challenge/val-v0.4/val/annotations.json'\n\ntest_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\ntest_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'","metadata":{"papermill":{"duration":0.023515,"end_time":"2021-05-10T15:30:39.772833","exception":false,"start_time":"2021-05-10T15:30:39.749318","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load JSON into a COCO api\ndef getCOCO(anns_path):\n    # Initialize the COCO api for instance annotations\n    coco = COCO(anns_path)\n    \n    # Load the categories in a variable\n    catIDs = coco.getCatIds()\n    cats = coco.loadCats(catIDs)\n    \n    # Print number of categories\n    nms = [cat['name'] for cat in cats]\n    \n    # Create a dataframe of the count of each category\n    df = pd.DataFrame(columns=['Category', 'ID', 'Count'])\n    \n    # Add each category and its count row by row\n    for i, catID in enumerate(catIDs):\n        imgIds = coco.getImgIds(catIds=catID)\n        df.loc[i] = [nms[i]] + [catID] + [len(imgIds)]\n    \n    return coco, df","metadata":{"papermill":{"duration":0.025932,"end_time":"2021-05-10T15:30:39.815028","exception":false,"start_time":"2021-05-10T15:30:39.789096","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the annotations of the image dataset\ntrain_coco, train_classes = getCOCO(train_anns_path)\nval_coco, val_classes = getCOCO(val_anns_path)\ntest_coco, test_classes = getCOCO(test_anns_path)","metadata":{"_kg_hide-output":true,"papermill":{"duration":6.871897,"end_time":"2021-05-10T15:30:46.704246","exception":false,"start_time":"2021-05-10T15:30:39.832349","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMask(image_id, coco, classes, image_size):\n    # Create a zero array with the given size and number of classes\n    mask = np.zeros((image_size[0], image_size[1], 274))\n\n    annIds = coco.getAnnIds(int(image_id))\n    anns = coco.loadAnns(annIds)\n\n    for i, ann in enumerate(anns):\n        # Get the binary mask for the annotation\n        binary = cv2.resize(coco.annToMask(ann), image_size, interpolation=cv2.INTER_AREA)\n\n        # Get the channel index for the annotation\n        channel = classes[classes.ID == ann['category_id']].index[0] + 1\n\n        # Update the channel of the annotation\n        mask[:, :, channel] = binary\n\n        # Update the background channel of the annotation\n        if i == 0:\n            mask[:, :, 0] = np.logical_or(mask[:, :, 0], np.logical_not(binary))\n        else:\n            mask[:, :, 0] = np.logical_and(mask[:, :, 0], np.logical_not(binary))\n\n    return mask","metadata":{"papermill":{"duration":0.027807,"end_time":"2021-05-10T15:30:46.750343","exception":false,"start_time":"2021-05-10T15:30:46.722536","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getGenerator(path, coco, classes, image_size, batch_size, augment=False):\n    c = 0\n    n = os.listdir(path)\n    random.shuffle(n)\n    \n    geo_aug = iaa.Fliplr(1.0)\n    \n    while (True):\n        img_batch = np.zeros((batch_size, image_size[0], image_size[1], 3)).astype('int')\n        mask_batch = np.zeros((batch_size, image_size[0], image_size[1], 274)).astype('float')\n\n        for i in range(c, c + batch_size):\n            img = cv2.imread(path + '/' + n[i])\n            img =  cv2.resize(img, image_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            mask = getMask(n[i][1:-4], coco, classes, image_size)\n            \n            if augment == True:\n                if random.randrange(10) % 2 == 0:\n                    img = geo_aug(image=img)\n                    mask = geo_aug(image=mask)            \n            \n            img_batch[i-c] = img\n            mask_batch[i-c] = mask\n\n        c += batch_size\n        if(c + batch_size >= len(os.listdir(path))):\n            c = 0\n            random.shuffle(n)\n\n        yield img_batch, mask_batch","metadata":{"papermill":{"duration":0.029955,"end_time":"2021-05-10T15:30:46.798268","exception":false,"start_time":"2021-05-10T15:30:46.768313","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the generators from the paths\ntrain_gen = getGenerator(train_imgs_path, train_coco, train_classes, IMAGE_SIZE, BATCH_SIZE, True)\n\ntrain_length = len(os.listdir(train_imgs_path))\nprint('Number of training images: {}'.format(train_length))\n\nval_gen = getGenerator(val_imgs_path, val_coco, val_classes, IMAGE_SIZE, BATCH_SIZE)\n\nval_length = len(os.listdir(val_imgs_path))\nprint('Number of validation images: {}'.format(val_length))\n\ntest_gen = getGenerator(test_imgs_path, test_coco, test_classes, IMAGE_SIZE, BATCH_SIZE)\n\ntest_length = len(os.listdir(test_imgs_path))\nprint('Number of test images: {}'.format(test_length))","metadata":{"papermill":{"duration":1.326913,"end_time":"2021-05-10T15:30:48.143595","exception":false,"start_time":"2021-05-10T15:30:46.816682","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualise(path, coco, classes, image_size, batch_size, augment=False):\n    temp_gen = getGenerator(path, coco, classes, image_size, batch_size, augment)\n    images, masks = next(temp_gen)\n    \n    for i in range(batch_size):\n        plt.figure(figsize=(6, 16))\n        \n        plt.subplot(1, 2, 1)\n        plt.title('Image')\n        plt.imshow(images[i])\n        plt.axis('off')\n        \n        plt.subplot(1, 2, 2)\n        plt.title('True Mask')\n        \n        true_mask = masks[i]\n        for c in range(274):\n            true_mask[:, :, c] = true_mask[:, :, c] * (c+1)\n            \n        plt.imshow(np.max(true_mask, axis=2))\n        plt.axis('off')\n        \n        plt.show()","metadata":{"papermill":{"duration":0.031458,"end_time":"2021-05-10T15:30:48.195548","exception":false,"start_time":"2021-05-10T15:30:48.16409","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise a few samples images with their backgrounds and objects\nvisualise(train_imgs_path, train_coco, train_classes, IMAGE_SIZE, 3, True)","metadata":{"papermill":{"duration":1.01854,"end_time":"2021-05-10T15:30:49.234087","exception":false,"start_time":"2021-05-10T15:30:48.215547","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install and import the segmentation models library\n!pip install segmentation_models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","metadata":{"_kg_hide-output":true,"papermill":{"duration":11.774703,"end_time":"2021-05-10T15:31:01.048044","exception":false,"start_time":"2021-05-10T15:30:49.273341","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model to be trained\nmodel = sm.PSPNet('resnet152', encoder_weights='imagenet', encoder_freeze=True, \n                  input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), downsample_factor=4, \n                  classes=274, activation='softmax')\n\nmodel.compile('Adam', loss=sm.losses.cce_dice_loss, \n              metrics=[sm.metrics.IOUScore(), sm.metrics.Precision(), sm.metrics.Recall()])","metadata":{"papermill":{"duration":12.766019,"end_time":"2021-05-10T15:31:13.840684","exception":false,"start_time":"2021-05-10T15:31:01.074665","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the trained model weights\n# weights_path = '../input/food-recognition-model/weights.h5'\n# model.load_weights(weights_path)","metadata":{"papermill":{"duration":0.100971,"end_time":"2021-05-10T15:31:14.008781","exception":false,"start_time":"2021-05-10T15:31:13.90781","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the defined model on the dataset\nhistory = model.fit(train_gen, steps_per_epoch=train_length//BATCH_SIZE, \n                    validation_data=val_gen, validation_steps=val_length//BATCH_SIZE, \n                    epochs=EPOCHS)","metadata":{"_kg_hide-output":true,"papermill":{"duration":4999.620921,"end_time":"2021-05-10T16:54:33.724382","exception":false,"start_time":"2021-05-10T15:31:14.103461","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and iou score over the epochs\nplt.figure(figsize=(20, 6))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model IoU Score')\nplt.ylabel('IoU Score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"papermill":{"duration":0.570284,"end_time":"2021-05-10T16:54:34.556787","exception":false,"start_time":"2021-05-10T16:54:33.986503","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to the output\nmodel.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.368266,"end_time":"2021-05-10T16:54:35.192239","exception":false,"start_time":"2021-05-10T16:54:34.823973","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test generator\nscores = model.evaluate(test_gen, steps=test_length//BATCH_SIZE)\nprint('\\nLoss: {}'.format(round(scores[0], 3)))\nprint('Average IoU: {}'.format(round(scores[1], 3)))\nprint('Average Precision: {}'.format(round(scores[2], 3)))\nprint('Average Recall: {}'.format(round(scores[3], 3)))","metadata":{"papermill":{"duration":40.039253,"end_time":"2021-05-10T16:55:15.500923","exception":false,"start_time":"2021-05-10T16:54:35.46167","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, path, coco, classes, image_size, batch_size):\n    temp_gen = getGenerator(path, coco, classes, image_size, batch_size)\n    images, masks = next(temp_gen)\n    prediction = model.predict(images)\n    \n    for i in range(batch_size):\n        plt.figure(figsize=(10, 20))\n        \n        plt.subplot(1, 3, 1)\n        plt.title('Image')\n        plt.imshow(images[i])\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 2)\n        plt.title('True Mask')\n        \n        true_mask = masks[i]\n        for c in range(274):\n            true_mask[:, :, c] = true_mask[:, :, c] * (c+1)\n            \n        plt.imshow(np.max(true_mask, axis=2))\n        plt.axis('off')\n        \n        pred_mask = np.round(prediction[i])\n        for c in range(274):\n            pred_mask[:, :, c] = pred_mask[:, :, c] * (c+1)\n            \n        plt.subplot(1, 3, 3)\n        plt.title('Predicted Mask')\n        plt.imshow(np.max(pred_mask, axis=2))\n        plt.axis('off')\n        \n        plt.show()","metadata":{"papermill":{"duration":0.279193,"end_time":"2021-05-10T16:55:16.0496","exception":false,"start_time":"2021-05-10T16:55:15.770407","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise the predictions and the true masks\npredict(model, test_imgs_path, test_coco, test_classes, IMAGE_SIZE, 3)","metadata":{"papermill":{"duration":1.425706,"end_time":"2021-05-10T16:55:17.740864","exception":false,"start_time":"2021-05-10T16:55:16.315158","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}