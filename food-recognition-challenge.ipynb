{"cells":[{"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-04-05T06:40:57.260859Z","iopub.status.busy":"2021-04-05T06:40:57.260184Z","iopub.status.idle":"2021-04-05T06:41:14.376512Z","shell.execute_reply":"2021-04-05T06:41:14.377063Z"},"papermill":{"duration":17.136133,"end_time":"2021-04-05T06:41:14.377452","exception":false,"start_time":"2021-04-05T06:40:57.241319","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Install the pycoco library\n!pip install pycocotools","execution_count":1,"outputs":[{"output_type":"stream","text":"Requirement already satisfied: pycocotools in /opt/conda/lib/python3.7/site-packages (2.0.2)\r\nRequirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.4.0)\r\nRequirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20210108)\r\nRequirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.22)\r\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\r\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\r\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\r\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\r\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (7.2.0)\r\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\r\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\r\n","name":"stdout"}]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:14.419115Z","iopub.status.busy":"2021-04-05T06:41:14.418487Z","iopub.status.idle":"2021-04-05T06:41:16.630784Z","shell.execute_reply":"2021-04-05T06:41:16.630067Z"},"papermill":{"duration":2.233957,"end_time":"2021-04-05T06:41:16.630936","exception":false,"start_time":"2021-04-05T06:41:14.396979","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport random\nimport cv2\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport imgaug as ia\nimport imgaug.augmenters as iaa","execution_count":2,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:16.673535Z","iopub.status.busy":"2021-04-05T06:41:16.672855Z","iopub.status.idle":"2021-04-05T06:41:16.675575Z","shell.execute_reply":"2021-04-05T06:41:16.676154Z"},"papermill":{"duration":0.026806,"end_time":"2021-04-05T06:41:16.67638","exception":false,"start_time":"2021-04-05T06:41:16.649574","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Define the image and annotation paths\ntrain_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\ntrain_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n\nval_imgs_path = '../input/food-recognition-challenge/val-v0.4/val/images'\nval_anns_path = '../input/food-recognition-challenge/val-v0.4/val/annotations.json'\n\ntest_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\ntest_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'","execution_count":3,"outputs":[]},{"metadata":{"papermill":{"duration":0.018781,"end_time":"2021-04-05T06:41:16.714254","exception":false,"start_time":"2021-04-05T06:41:16.695473","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Reference to Image Segmentation\n\nhttps://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html"},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:16.761893Z","iopub.status.busy":"2021-04-05T06:41:16.760857Z","iopub.status.idle":"2021-04-05T06:41:16.764338Z","shell.execute_reply":"2021-04-05T06:41:16.763681Z"},"papermill":{"duration":0.030909,"end_time":"2021-04-05T06:41:16.76448","exception":false,"start_time":"2021-04-05T06:41:16.733571","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Function to load JSON into a COCO api\ndef getCOCO(anns_path):\n    # Initialize the COCO api for instance annotations\n    coco = COCO(anns_path)\n    \n    # Load the categories in a variable\n    catIDs = coco.getCatIds()\n    cats = coco.loadCats(catIDs)\n    \n    # Print number of categories\n    nms = [cat['name'] for cat in cats]\n    print('\\nNumber of COCO categories: {}'.format(len(nms)))\n    \n    # Create a dataframe of the count of each category\n    df = pd.DataFrame(columns=['Category', 'Count'])\n    \n    # Add each category and its count row by row\n    for i, catID in enumerate(catIDs):\n        imgIds = coco.getImgIds(catIds=catID)\n        df.loc[i] = [nms[i]] + [len(imgIds)]\n        \n    # Sort the values in descending order of count\n    df = df.sort_values('Count', ascending=False).reset_index(drop=True)        \n        \n    return coco, df","execution_count":4,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:16.807677Z","iopub.status.busy":"2021-04-05T06:41:16.806978Z","iopub.status.idle":"2021-04-05T06:41:17.88779Z","shell.execute_reply":"2021-04-05T06:41:17.888307Z"},"papermill":{"duration":1.104816,"end_time":"2021-04-05T06:41:17.888484","exception":false,"start_time":"2021-04-05T06:41:16.783668","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Load the annotations of the image dataset\ncoco, classes = getCOCO(train_anns_path)\n\n# Preview a sample of the classes dataframe\nclasses.head()","execution_count":5,"outputs":[{"output_type":"stream","text":"loading annotations into memory...\nDone (t=2.60s)\ncreating index...\nindex created!\n\nNumber of COCO categories: 273\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"                 Category Count\n0                   water  1835\n1             bread-white  1273\n2  salad-leaf-salad-green  1189\n3                  tomato  1069\n4                  butter  1008","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>water</td>\n      <td>1835</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bread-white</td>\n      <td>1273</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>salad-leaf-salad-green</td>\n      <td>1189</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tomato</td>\n      <td>1069</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>butter</td>\n      <td>1008</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"papermill":{"duration":0.020591,"end_time":"2021-04-05T06:41:17.9291","exception":false,"start_time":"2021-04-05T06:41:17.908509","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Reference for Getting Masks\n\nhttps://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function that gets images. \n# It is useful possible to get just a subset of images by setting subset to True. This option\n# can be useful for example to make first attempts of training without using the whole training set\ndef getImgs(path, image_size, subset=False, subset_size=500):\n    # Get all image Ids\n    imgIds = coco.getImgIds()\n    images = coco.loadImgs(imgIds)\n    \n    if subset:\n        images = random.sample(images, subset_size)\n    \n    # Get all annotation Ids\n    annIds = coco.getAnnIds()\n    anns = coco.loadAnns(annIds)\n    \n    img_lst = []\n    msk_lst = []\n    obj_lst = []\n    \n    for file in images:\n        # Read the image from the full file path\n        img = cv2.imread(path + '/' + file['file_name'])\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # Resize the image to the given size\n        img = cv2.resize(img, image_size)\n        \n        # Create a zero array for the mask with the given size\n        full_mask = np.zeros(image_size)\n        \n        # Create a list to save the name of each object of the mask\n        obj_names = []\n        \n        for i, ann in enumerate(anns):\n            # Check if the annotation belongs to the current image\n            if ann['image_id'] == file['id']:\n                annotation = anns.pop(i)\n                \n                # Get the category's name from the annotation's category Id\n                category = coco.loadCats(annotation['category_id'])[0]['name']\n                obj_names.append(category)\n                \n                # Label each object in the mask with its pixel value from the classes dataframe\n                # The values are incremented by 1 so that only the background (no object) has a pixel value of 0\n                mask = coco.annToMask(annotation) * (classes[classes.Category == category].index[0] + 1)\n                \n                # Resize and merge the mask for each object in the image\n                mask = cv2.resize(mask, image_size)\n                full_mask = np.maximum(mask, full_mask)\n        \n        # Normalise the image and mask to a value between 0 and 1\n        norm_img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n        norm_mask = cv2.normalize(full_mask, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n        \n        img_lst.append(norm_img)\n        msk_lst.append(norm_mask)\n        obj_lst.append(obj_names)\n                \n    return img_lst, msk_lst, obj_lst","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the images and masks from the given path\nimages, masks, objects = getImgs(train_imgs_path, (224, 224), subset=True, subset_size=500)\n\n# Check if the number of images and masks are the same\nprint('Number of images: {}'.format(len(images)))\nprint('Number of masks: {}'.format(len(masks)))","execution_count":7,"outputs":[{"output_type":"stream","text":"Number of images: 500\nNumber of masks: 500\n","name":"stdout"}]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:53.982939Z","iopub.status.busy":"2021-04-05T06:41:53.982171Z","iopub.status.idle":"2021-04-05T06:41:53.98537Z","shell.execute_reply":"2021-04-05T06:41:53.984872Z"},"papermill":{"duration":0.032169,"end_time":"2021-04-05T06:41:53.985526","exception":false,"start_time":"2021-04-05T06:41:53.953357","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Function to show a sample image with its mask\ndef showSamp(imgs, msks, objs, n=None):\n    plt.figure(figsize=(10, 10))\n    length = len(imgs)\n    \n    if n is None:\n        n = random.randrange(length)\n    \n    ax1 = plt.subplot(1, 2, 1)\n    ax1.imshow(imgs[n])\n    ax1.axis('off')\n    ax1.title.set_text('Sample Image')\n    \n    ax2 = plt.subplot(1, 2, 2)\n    ax2.imshow(msks[n])\n    ax2.axis('off')\n    ax2.title.set_text('Sample Mask')\n    \n    for i, e in enumerate(objs[n]):\n        if i == 0:\n            objects = e\n        else:\n            objects += ', ' + e\n    print('Objects: {}'.format(objects))\n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:54.050896Z","iopub.status.busy":"2021-04-05T06:41:54.050202Z","iopub.status.idle":"2021-04-05T06:41:54.271556Z","shell.execute_reply":"2021-04-05T06:41:54.272072Z"},"papermill":{"duration":0.265837,"end_time":"2021-04-05T06:41:54.272248","exception":false,"start_time":"2021-04-05T06:41:54.006411","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Show sample images and masks\nshowSamp(images, masks, objects)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.025165,"end_time":"2021-04-05T06:41:54.32297","exception":false,"start_time":"2021-04-05T06:41:54.297805","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Reference for Augmentation\n\nhttps://github.com/aleju/imgaug"},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:54.377154Z","iopub.status.busy":"2021-04-05T06:41:54.376522Z","iopub.status.idle":"2021-04-05T06:41:54.38367Z","shell.execute_reply":"2021-04-05T06:41:54.384174Z"},"papermill":{"duration":0.036025,"end_time":"2021-04-05T06:41:54.384398","exception":false,"start_time":"2021-04-05T06:41:54.348373","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Function to augment the images and masks\ngeo_seq = iaa.Sequential([\n    iaa.Fliplr(1), # horizontally flip the images\n])\n\nint_seq = iaa.Sequential([\n    iaa.GaussianBlur(sigma=(0, 5.0)) # blur images with a sigma of 0 to 5.0\n])\n\ndef augment_img(img, msk):\n    geo_aug = geo_seq.to_deterministic()\n    int_aug = int_seq.to_deterministic()\n    \n    # Apply geographic augmentation to image and mask\n    img_aug = geo_aug.augment_image(img)\n    msk_aug = geo_aug.augment_image(msk)\n    \n    # Apply intensity augmentation to image only\n    img_aug = int_aug.augment_image(img_aug) \n    \n    return img_aug, msk_aug","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:54.43908Z","iopub.status.busy":"2021-04-05T06:41:54.438431Z","iopub.status.idle":"2021-04-05T06:41:54.446891Z","shell.execute_reply":"2021-04-05T06:41:54.447391Z"},"papermill":{"duration":0.037676,"end_time":"2021-04-05T06:41:54.447608","exception":false,"start_time":"2021-04-05T06:41:54.409932","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Function to show an image and a mask along with their augments\ndef showAug(imgs, msks, n=None):\n    plt.figure(figsize=(10, 10))\n    length = len(imgs)\n    \n    if n is None:\n        n = random.randrange(length)\n        \n    img_aug, msk_aug = augment_img(imgs[n], msks[n])\n    \n    ax1 = plt.subplot(2, 2, 1)\n    ax1.imshow(imgs[n])\n    ax1.axis('off')\n    ax1.title.set_text('Original Image')\n    \n    ax2 = plt.subplot(2, 2, 2)\n    ax2.imshow(img_aug)\n    ax2.axis('off')\n    ax2.title.set_text('Augmented Image')\n    \n    ax3 = plt.subplot(2, 2, 3)\n    ax3.imshow(msks[n])\n    ax3.axis('off')\n    ax3.title.set_text('Original Mask')\n    \n    ax4 = plt.subplot(2, 2, 4)\n    ax4.imshow(msk_aug)\n    ax4.axis('off')\n    ax4.title.set_text('Augmented Mask')    \n    \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:54.505783Z","iopub.status.busy":"2021-04-05T06:41:54.505041Z","iopub.status.idle":"2021-04-05T06:41:54.898003Z","shell.execute_reply":"2021-04-05T06:41:54.89855Z"},"papermill":{"duration":0.42548,"end_time":"2021-04-05T06:41:54.89873","exception":false,"start_time":"2021-04-05T06:41:54.47325","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Show sample images and masks with their augments\nshowAug(images, masks)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:54.966858Z","iopub.status.busy":"2021-04-05T06:41:54.966128Z","iopub.status.idle":"2021-04-05T06:41:54.972244Z","shell.execute_reply":"2021-04-05T06:41:54.972806Z"},"papermill":{"duration":0.041642,"end_time":"2021-04-05T06:41:54.972983","exception":false,"start_time":"2021-04-05T06:41:54.931341","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#  Function to create and shuffle a list of original and augmented images and masks\ndef getAugs(imgs, msks, K):\n    length = len(imgs)\n    \n    img_lst = imgs.copy()\n    msk_lst = msks.copy()\n    \n    for i in range(K):\n        n = random.randrange(length)\n        img_aug, msk_aug = augment_img(imgs[n], msks[n])\n        \n        img_lst.append(img_aug)\n        msk_lst.append(msk_aug)\n    \n    # Shuffle all the original and augmented images and masks\n    z = list(zip(img_lst, msk_lst))\n    random.shuffle(z)\n    img_lst, msk_lst = zip(*z)\n    \n    return img_lst, msk_lst","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:41:55.040948Z","iopub.status.busy":"2021-04-05T06:41:55.040311Z","iopub.status.idle":"2021-04-05T06:41:55.18656Z","shell.execute_reply":"2021-04-05T06:41:55.187039Z"},"papermill":{"duration":0.181794,"end_time":"2021-04-05T06:41:55.187223","exception":false,"start_time":"2021-04-05T06:41:55.005429","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Augment a given number of images and masks\naug_images, aug_masks = getAugs(images, masks, 10)\n\n# Show the number of augmented images and masks\nprint('Number of augmented images: {}'.format(len(aug_images)))\nprint('Number of augmented masks: {}'.format(len(aug_masks)))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.032477,"end_time":"2021-04-05T06:41:55.252524","exception":false,"start_time":"2021-04-05T06:41:55.220047","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Reference for Model Building\n\nhttps://github.com/qubvel/segmentation_models#quick-start\n\nhttps://github.com/qubvel/segmentation_models/issues/374"},{"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-04-05T06:41:55.33902Z","iopub.status.busy":"2021-04-05T06:41:55.337066Z","iopub.status.idle":"2021-04-05T06:42:09.056007Z","shell.execute_reply":"2021-04-05T06:42:09.056521Z"},"papermill":{"duration":13.771542,"end_time":"2021-04-05T06:42:09.056718","exception":false,"start_time":"2021-04-05T06:41:55.285176","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Install and import the segmentation models library\n!pip install segmentation_models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:42:09.141919Z","iopub.status.busy":"2021-04-05T06:42:09.141241Z","iopub.status.idle":"2021-04-05T06:42:15.173759Z","shell.execute_reply":"2021-04-05T06:42:15.173149Z"},"papermill":{"duration":6.077549,"end_time":"2021-04-05T06:42:15.173923","exception":false,"start_time":"2021-04-05T06:42:09.096374","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Define the model to be trained\nBACKBONE = 'resnet34'\nmodel = sm.Unet(BACKBONE, encoder_weights='imagenet')\nmodel.compile('Adam', loss=sm.losses.bce_jaccard_loss, metrics=[sm.metrics.iou_score])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T06:42:15.304529Z","iopub.status.busy":"2021-04-05T06:42:15.303814Z","iopub.status.idle":"2021-04-05T08:45:46.78202Z","shell.execute_reply":"2021-04-05T08:45:46.782617Z"},"papermill":{"duration":7411.546199,"end_time":"2021-04-05T08:45:46.782867","exception":false,"start_time":"2021-04-05T06:42:15.236668","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Train the defined model on the dataset\nhistory = model.fit(x=np.array(aug_images), y=np.array(aug_masks), batch_size=16, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T08:45:47.418252Z","iopub.status.busy":"2021-04-05T08:45:47.417581Z","iopub.status.idle":"2021-04-05T08:45:47.717617Z","shell.execute_reply":"2021-04-05T08:45:47.718121Z"},"papermill":{"duration":0.624407,"end_time":"2021-04-05T08:45:47.71833","exception":false,"start_time":"2021-04-05T08:45:47.093923","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Plot the loss and iou score over the epochs\nfig = plt.figure(figsize=(16, 8))\nax1 = fig.add_subplot(111)\nax2 = ax1.twinx()\n\np1, = ax1.plot(history.history['iou_score'], 'g')\nax1.set_ylabel('IOU Score')\n\np2, = ax2.plot(history.history['loss'], 'r')\nax2.set_ylabel('Loss')\n\nax1.legend([p1, p2], ['IOU Score', 'Loss'], loc='best')\n\nplt.title('Model History Over Epochs')\nplt.xlabel('Epochs')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2021-04-05T08:45:48.345148Z","iopub.status.busy":"2021-04-05T08:45:48.344491Z","iopub.status.idle":"2021-04-05T08:45:49.079909Z","shell.execute_reply":"2021-04-05T08:45:49.08064Z"},"papermill":{"duration":1.051097,"end_time":"2021-04-05T08:45:49.08085","exception":false,"start_time":"2021-04-05T08:45:48.029753","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Save the model to the output\nmodel.save('trained_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}