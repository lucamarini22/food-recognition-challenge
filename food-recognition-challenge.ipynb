{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "czech-symposium",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:08.064452Z",
     "iopub.status.busy": "2021-04-27T13:10:08.063664Z",
     "iopub.status.idle": "2021-04-27T13:10:22.776757Z",
     "shell.execute_reply": "2021-04-27T13:10:22.775609Z"
    },
    "papermill": {
     "duration": 14.733796,
     "end_time": "2021-04-27T13:10:22.776939",
     "exception": false,
     "start_time": "2021-04-27T13:10:08.043143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\r\n",
      "  Downloading pycocotools-2.0.2.tar.gz (23 kB)\r\n",
      "Requirement already satisfied: setuptools>=18.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (49.6.0.post20210108)\r\n",
      "Requirement already satisfied: cython>=0.27.3 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (0.29.23)\r\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in /opt/conda/lib/python3.7/site-packages (from pycocotools) (3.4.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (7.2.0)\r\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (1.19.5)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\r\n",
      "Building wheels for collected packages: pycocotools\r\n",
      "  Building wheel for pycocotools (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.2-cp37-cp37m-linux_x86_64.whl size=272454 sha256=3eeeb91152a3615ad201ab0baaa80a0153a3affdb73162251302fd2198b2284b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/cf/1b/e95c99c5f9d1648be3f500ca55e7ce55f24818b0f48336adaf\r\n",
      "Successfully built pycocotools\r\n",
      "Installing collected packages: pycocotools\r\n",
      "Successfully installed pycocotools-2.0.2\r\n"
     ]
    }
   ],
   "source": [
    "# Install the pycoco library\n",
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "plastic-midnight",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:22.826822Z",
     "iopub.status.busy": "2021-04-27T13:10:22.826136Z",
     "iopub.status.idle": "2021-04-27T13:10:22.953958Z",
     "shell.execute_reply": "2021-04-27T13:10:22.954909Z"
    },
    "papermill": {
     "duration": 0.156585,
     "end_time": "2021-04-27T13:10:22.955111",
     "exception": false,
     "start_time": "2021-04-27T13:10:22.798526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "labeled-delivery",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:23.015535Z",
     "iopub.status.busy": "2021-04-27T13:10:23.013947Z",
     "iopub.status.idle": "2021-04-27T13:10:23.016514Z",
     "shell.execute_reply": "2021-04-27T13:10:23.015999Z"
    },
    "papermill": {
     "duration": 0.040616,
     "end_time": "2021-04-27T13:10:23.016627",
     "exception": false,
     "start_time": "2021-04-27T13:10:22.976011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the image and annotation paths\n",
    "train_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\n",
    "train_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n",
    "\n",
    "val_imgs_path = '../input/food-recognition-challenge/val-v0.4/val/images'\n",
    "val_anns_path = '../input/food-recognition-challenge/val-v0.4/val/annotations.json'\n",
    "\n",
    "test_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\n",
    "test_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-prefix",
   "metadata": {
    "papermill": {
     "duration": 0.013742,
     "end_time": "2021-04-27T13:10:23.046129",
     "exception": false,
     "start_time": "2021-04-27T13:10:23.032387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference to Image Segmentation\n",
    "\n",
    "https://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aerial-sunglasses",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:23.079343Z",
     "iopub.status.busy": "2021-04-27T13:10:23.078637Z",
     "iopub.status.idle": "2021-04-27T13:10:23.081199Z",
     "shell.execute_reply": "2021-04-27T13:10:23.080816Z"
    },
    "papermill": {
     "duration": 0.021707,
     "end_time": "2021-04-27T13:10:23.081318",
     "exception": false,
     "start_time": "2021-04-27T13:10:23.059611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to load JSON into a COCO api\n",
    "def getCOCO(anns_path):\n",
    "    # Initialize the COCO api for instance annotations\n",
    "    coco = COCO(anns_path)\n",
    "    \n",
    "    # Load the categories in a variable\n",
    "    catIDs = coco.getCatIds()\n",
    "    cats = coco.loadCats(catIDs)\n",
    "    \n",
    "    # Print number of categories\n",
    "    nms = [cat['name'] for cat in cats]\n",
    "    print('\\nNumber of COCO categories: {}'.format(len(nms)))\n",
    "    \n",
    "    # Create a dataframe of the count of each category\n",
    "    df = pd.DataFrame(columns=['Category', 'ID', 'Count'])\n",
    "    \n",
    "    # Add each category and its count row by row\n",
    "    for i, catID in enumerate(catIDs):\n",
    "        imgIds = coco.getImgIds(catIds=catID)\n",
    "        df.loc[i] = [nms[i]] + [catID] + [len(imgIds)]     \n",
    "        \n",
    "    return coco, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "derived-dress",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:23.111630Z",
     "iopub.status.busy": "2021-04-27T13:10:23.111096Z",
     "iopub.status.idle": "2021-04-27T13:10:27.585623Z",
     "shell.execute_reply": "2021-04-27T13:10:27.586124Z"
    },
    "papermill": {
     "duration": 4.491496,
     "end_time": "2021-04-27T13:10:27.586299",
     "exception": false,
     "start_time": "2021-04-27T13:10:23.094803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.70s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "Number of COCO categories: 273\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>ID</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>water</td>\n",
       "      <td>2578</td>\n",
       "      <td>1835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pear</td>\n",
       "      <td>1157</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>egg</td>\n",
       "      <td>2022</td>\n",
       "      <td>626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grapes</td>\n",
       "      <td>1198</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butter</td>\n",
       "      <td>2053</td>\n",
       "      <td>1008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category    ID Count\n",
       "0    water  2578  1835\n",
       "1     pear  1157   151\n",
       "2      egg  2022   626\n",
       "3   grapes  1198    94\n",
       "4   butter  2053  1008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the annotations of the image dataset\n",
    "coco, classes = getCOCO(train_anns_path)\n",
    "\n",
    "# Preview a sample of the classes dataframe\n",
    "classes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-emerald",
   "metadata": {
    "papermill": {
     "duration": 0.014499,
     "end_time": "2021-04-27T13:10:27.615838",
     "exception": false,
     "start_time": "2021-04-27T13:10:27.601339",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference for Getting Masks\n",
    "\n",
    "https://towardsdatascience.com/master-the-coco-dataset-for-semantic-image-segmentation-part-2-of-2-c0d1f593096a\n",
    "\n",
    "https://github.com/virafpatrawala/COCO-Semantic-Segmentation/blob/master/COCOdataset_SemanticSegmentation_Demo.ipynb\n",
    "\n",
    "https://github.com/qubvel/segmentation_models/issues/137\n",
    "\n",
    "https://www.reddit.com/r/computervision/comments/ihh8n0/onehotencoding_with_multichannel_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "global-think",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:27.651978Z",
     "iopub.status.busy": "2021-04-27T13:10:27.651417Z",
     "iopub.status.idle": "2021-04-27T13:10:27.654399Z",
     "shell.execute_reply": "2021-04-27T13:10:27.653999Z"
    },
    "papermill": {
     "duration": 0.023872,
     "end_time": "2021-04-27T13:10:27.654501",
     "exception": false,
     "start_time": "2021-04-27T13:10:27.630629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getMask(image_id):\n",
    "    # Create a zero array with the given size and number of classes\n",
    "    mask = np.zeros((224, 224, 274))\n",
    "\n",
    "    annIds = coco.getAnnIds(int(image_id))\n",
    "    anns = coco.loadAnns(annIds)\n",
    "\n",
    "    for i, ann in enumerate(anns):\n",
    "        # Get the binary mask for the annotation\n",
    "        binary = cv2.resize(coco.annToMask(ann), (224, 224))\n",
    "\n",
    "        # Get the channel index for the annotation\n",
    "        channel = classes[classes.ID == ann['category_id']].index[0] + 1\n",
    "\n",
    "        # Update the channel of the annotation\n",
    "        mask[:, :, channel] = binary\n",
    "\n",
    "        # Update the background channel of the annotation\n",
    "        if i == 0:\n",
    "            mask[:, :, 0] = np.logical_or(mask[:, :, 0], np.logical_not(binary))\n",
    "        else:\n",
    "            mask[:, :, 0] = np.logical_and(mask[:, :, 0], np.logical_not(binary))\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "grave-software",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:27.691114Z",
     "iopub.status.busy": "2021-04-27T13:10:27.690423Z",
     "iopub.status.idle": "2021-04-27T13:10:27.693125Z",
     "shell.execute_reply": "2021-04-27T13:10:27.692742Z"
    },
    "papermill": {
     "duration": 0.02426,
     "end_time": "2021-04-27T13:10:27.693253",
     "exception": false,
     "start_time": "2021-04-27T13:10:27.668993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getGenerator(img_folder, batch_size):\n",
    "    c = 0\n",
    "    n = os.listdir(img_folder)\n",
    "    random.shuffle(n)\n",
    "    \n",
    "    while (True):\n",
    "        img_batch = np.zeros((batch_size, 224, 224, 3)).astype('int')\n",
    "        mask_batch = np.zeros((batch_size, 224, 224, 274)).astype('int')\n",
    "\n",
    "        for i in range(c, c + batch_size):\n",
    "            img = cv2.imread(img_folder + '/' + n[i])\n",
    "            img =  cv2.resize(img, (224, 224))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_batch[i-c] = img\n",
    "\n",
    "            mask = getMask(n[i][1:-4])\n",
    "            mask_batch[i-c] = mask\n",
    "\n",
    "        c += batch_size\n",
    "        if(c + batch_size >= len(os.listdir(img_folder))):\n",
    "            c = 0\n",
    "            random.shuffle(n)\n",
    "\n",
    "        yield img_batch, mask_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "entire-financing",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:27.727689Z",
     "iopub.status.busy": "2021-04-27T13:10:27.727166Z",
     "iopub.status.idle": "2021-04-27T13:10:29.500887Z",
     "shell.execute_reply": "2021-04-27T13:10:29.500012Z"
    },
    "papermill": {
     "duration": 1.793134,
     "end_time": "2021-04-27T13:10:29.501012",
     "exception": false,
     "start_time": "2021-04-27T13:10:27.707878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 24120\n",
      "Number of validation images: 1269\n",
      "Number of test images: 1269\n"
     ]
    }
   ],
   "source": [
    "# Get the generators from the paths\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_gen = getGenerator(train_imgs_path, batch_size=BATCH_SIZE)\n",
    "train_length = len(os.listdir(train_imgs_path))\n",
    "print('Number of training images: {}'.format(train_length))\n",
    "\n",
    "val_gen = getGenerator(val_imgs_path, batch_size=BATCH_SIZE)\n",
    "val_length = len(os.listdir(val_imgs_path))\n",
    "print('Number of validation images: {}'.format(val_length))\n",
    "\n",
    "test_gen = getGenerator(test_imgs_path, batch_size=BATCH_SIZE)\n",
    "test_length = len(os.listdir(test_imgs_path))\n",
    "print('Number of test images: {}'.format(test_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compliant-turkish",
   "metadata": {
    "papermill": {
     "duration": 0.01546,
     "end_time": "2021-04-27T13:10:29.532703",
     "exception": false,
     "start_time": "2021-04-27T13:10:29.517243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference for Model Building\n",
    "\n",
    "https://github.com/qubvel/segmentation_models#quick-start\n",
    "\n",
    "https://github.com/qubvel/segmentation_models/issues/374\n",
    "\n",
    "https://github.com/qubvel/segmentation_models/blob/master/examples/multiclass%20segmentation%20(camvid).ipynb\n",
    "\n",
    "https://github.com/qubvel/segmentation_models/issues/254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "temporal-parts",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:29.574871Z",
     "iopub.status.busy": "2021-04-27T13:10:29.573853Z",
     "iopub.status.idle": "2021-04-27T13:10:41.925047Z",
     "shell.execute_reply": "2021-04-27T13:10:41.925802Z"
    },
    "papermill": {
     "duration": 12.377572,
     "end_time": "2021-04-27T13:10:41.925967",
     "exception": false,
     "start_time": "2021-04-27T13:10:29.548395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting segmentation_models\r\n",
      "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\r\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7\r\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\r\n",
      "\u001b[K     |████████████████████████████████| 50 kB 4.4 MB/s \r\n",
      "\u001b[?25hCollecting efficientnet==1.0.0\r\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\r\n",
      "Collecting image-classifiers==1.0.0\r\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\r\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation_models) (0.18.1)\r\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (2.10.0)\r\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.19.5)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.15.0)\r\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.9.0)\r\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.5.4)\r\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.1.1)\r\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.5)\r\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.4.1)\r\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (7.2.0)\r\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2021.4.8)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.8.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (0.10.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation_models) (2.4.7)\r\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation_models) (4.4.2)\r\n",
      "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation-models\r\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\r\n",
      "env: SM_FRAMEWORK=tf.keras\n",
      "Segmentation Models: using `tf.keras` framework.\n"
     ]
    }
   ],
   "source": [
    "# Install and import the segmentation models library\n",
    "!pip install segmentation_models\n",
    "%env SM_FRAMEWORK=tf.keras\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "identical-subscription",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:41.969723Z",
     "iopub.status.busy": "2021-04-27T13:10:41.968864Z",
     "iopub.status.idle": "2021-04-27T13:10:46.700242Z",
     "shell.execute_reply": "2021-04-27T13:10:46.699709Z"
    },
    "papermill": {
     "duration": 4.755183,
     "end_time": "2021-04-27T13:10:46.700366",
     "exception": false,
     "start_time": "2021-04-27T13:10:41.945183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet34_imagenet_1000_no_top.h5\n",
      "85524480/85521592 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Define the model to be trained\n",
    "model = sm.Unet('resnet34', encoder_weights='imagenet', classes=274, activation='softmax')\n",
    "model.compile('Adam', loss='categorical_crossentropy', metrics=[sm.metrics.iou_score, sm.metrics.precision, sm.metrics.recall])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "detailed-orientation",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:46.751476Z",
     "iopub.status.busy": "2021-04-27T13:10:46.750941Z",
     "iopub.status.idle": "2021-04-27T13:10:46.754808Z",
     "shell.execute_reply": "2021-04-27T13:10:46.754406Z"
    },
    "papermill": {
     "duration": 0.030459,
     "end_time": "2021-04-27T13:10:46.754915",
     "exception": false,
     "start_time": "2021-04-27T13:10:46.724456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load the trained model weights\n",
    "# weights_path = '../input/food-recognition-model/trained_model.h5'\n",
    "# model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sexual-indonesia",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-04-27T13:10:46.807935Z",
     "iopub.status.busy": "2021-04-27T13:10:46.807348Z",
     "iopub.status.idle": "2021-04-27T18:17:35.590740Z",
     "shell.execute_reply": "2021-04-27T18:17:35.591152Z"
    },
    "papermill": {
     "duration": 18408.811871,
     "end_time": "2021-04-27T18:17:35.591359",
     "exception": false,
     "start_time": "2021-04-27T13:10:46.779488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2412/2412 [==============================] - 6230s 3s/step - loss: 2.0464 - iou_score: 0.0027 - precision: 0.0062 - recall: 0.9477\n",
      "Epoch 2/3\n",
      "2412/2412 [==============================] - 6051s 3s/step - loss: 1.9657 - iou_score: 0.0027 - precision: 0.0061 - recall: 0.9478\n",
      "Epoch 3/3\n",
      "2412/2412 [==============================] - 6124s 3s/step - loss: 1.9375 - iou_score: 0.0028 - precision: 0.0067 - recall: 0.9478\n"
     ]
    }
   ],
   "source": [
    "# Train the defined model on the dataset\n",
    "history = model.fit(train_gen, steps_per_epoch=train_length//BATCH_SIZE, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "employed-rebound",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-27T18:17:40.117647Z",
     "iopub.status.busy": "2021-04-27T18:17:40.116924Z",
     "iopub.status.idle": "2021-04-27T18:17:40.399900Z",
     "shell.execute_reply": "2021-04-27T18:17:40.399169Z"
    },
    "papermill": {
     "duration": 2.924519,
     "end_time": "2021-04-27T18:17:40.400032",
     "exception": false,
     "start_time": "2021-04-27T18:17:37.475513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the model to the output\n",
    "model.save_weights('trained_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 18465.055933,
   "end_time": "2021-04-27T18:17:46.144802",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-27T13:10:01.088869",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
