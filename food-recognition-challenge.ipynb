{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the pycoco library\n!pip install pycocotools","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":15.241261,"end_time":"2021-04-29T07:09:35.685421","exception":false,"start_time":"2021-04-29T07:09:20.44416","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"papermill":{"duration":0.157371,"end_time":"2021-04-29T07:09:35.860328","exception":false,"start_time":"2021-04-29T07:09:35.702957","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the image and annotation paths\ntrain_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\ntrain_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n\ntest_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\ntest_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'","metadata":{"papermill":{"duration":0.021103,"end_time":"2021-04-29T07:09:35.896302","exception":false,"start_time":"2021-04-29T07:09:35.875199","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference to Image Segmentation\n\nhttps://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html","metadata":{"papermill":{"duration":0.01415,"end_time":"2021-04-29T07:09:35.924935","exception":false,"start_time":"2021-04-29T07:09:35.910785","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Function to load JSON into a COCO api\ndef getCOCO(anns_path):\n    # Initialize the COCO api for instance annotations\n    coco = COCO(anns_path)\n    \n    # Load the categories in a variable\n    catIDs = coco.getCatIds()\n    cats = coco.loadCats(catIDs)\n    \n    # Print number of categories\n    nms = [cat['name'] for cat in cats]\n    \n    # Create a dataframe of the count of each category\n    df = pd.DataFrame(columns=['Category', 'ID', 'Count'])\n    \n    # Add each category and its count row by row\n    for i, catID in enumerate(catIDs):\n        imgIds = coco.getImgIds(catIds=catID)\n        df.loc[i] = [nms[i]] + [catID] + [len(imgIds)]\n    \n    return coco, df","metadata":{"papermill":{"duration":0.022783,"end_time":"2021-04-29T07:09:35.961995","exception":false,"start_time":"2021-04-29T07:09:35.939212","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the annotations of the image dataset\ntrain_coco, train_classes = getCOCO(train_anns_path)\ntest_coco, test_classes = getCOCO(test_anns_path)","metadata":{"_kg_hide-output":true,"papermill":{"duration":5.883051,"end_time":"2021-04-29T07:09:41.859552","exception":false,"start_time":"2021-04-29T07:09:35.976501","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMask(image_id, coco, classes, image_size):\n    # Create a zero array with the given size and number of classes\n    mask = np.zeros((image_size[0], image_size[1], 274))\n\n    annIds = coco.getAnnIds(int(image_id))\n    anns = coco.loadAnns(annIds)\n\n    for i, ann in enumerate(anns):\n        # Get the binary mask for the annotation\n        binary = cv2.resize(coco.annToMask(ann), image_size)\n\n        # Get the channel index for the annotation\n        channel = classes[classes.ID == ann['category_id']].index[0] + 1\n\n        # Update the channel of the annotation\n        mask[:, :, channel] = binary\n\n        # Update the background channel of the annotation\n        if i == 0:\n            mask[:, :, 0] = np.logical_or(mask[:, :, 0], np.logical_not(binary))\n        else:\n            mask[:, :, 0] = np.logical_and(mask[:, :, 0], np.logical_not(binary))\n\n    return mask","metadata":{"papermill":{"duration":0.024192,"end_time":"2021-04-29T07:09:41.898818","exception":false,"start_time":"2021-04-29T07:09:41.874626","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getGenerator(img_folder, coco, classes, image_size, batch_size):\n    c = 0\n    n = os.listdir(img_folder)\n    random.shuffle(n)\n    \n    while (True):\n        img_batch = np.zeros((batch_size, image_size[0], image_size[1], 3)).astype('int')\n        mask_batch = np.zeros((batch_size, image_size[0], image_size[1], 274)).astype('float')\n\n        for i in range(c, c + batch_size):\n            img = cv2.imread(img_folder + '/' + n[i])\n            img =  cv2.resize(img, image_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img_batch[i-c] = img\n\n            mask = getMask(n[i][1:-4], coco, classes, image_size)\n            mask_batch[i-c] = mask\n\n        c += batch_size\n        if(c + batch_size >= len(os.listdir(img_folder))):\n            c = 0\n            random.shuffle(n)\n\n        yield img_batch, mask_batch","metadata":{"papermill":{"duration":0.025692,"end_time":"2021-04-29T07:09:41.938886","exception":false,"start_time":"2021-04-29T07:09:41.913194","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the generators from the paths\nIMAGE_SIZE = (32, 32)\nBATCH_SIZE = 300\n\ntrain_gen = getGenerator(train_imgs_path, train_coco, train_classes, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntrain_length = len(os.listdir(train_imgs_path))\nprint('Number of training images: {}'.format(train_length))\n\ntest_gen = getGenerator(test_imgs_path, test_coco, test_classes, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntest_length = len(os.listdir(test_imgs_path))\nprint('Number of test images: {}'.format(test_length))","metadata":{"papermill":{"duration":0.969098,"end_time":"2021-04-29T07:09:42.922674","exception":false,"start_time":"2021-04-29T07:09:41.953576","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install and import the segmentation models library\n!pip install segmentation_models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","metadata":{"_kg_hide-output":true,"papermill":{"duration":13.074859,"end_time":"2021-04-29T07:09:56.013018","exception":false,"start_time":"2021-04-29T07:09:42.938159","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model to be trained\nmodel = sm.Unet('resnet34', encoder_freeze=True, classes=274, activation='softmax')\nmodel.compile('Adam', loss=sm.losses.cce_dice_loss, \n              metrics=[sm.metrics.iou_score, sm.metrics.precision, sm.metrics.recall])","metadata":{"papermill":{"duration":5.475958,"end_time":"2021-04-29T07:10:01.509487","exception":false,"start_time":"2021-04-29T07:09:56.033529","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the trained model weights\n# weights_path = '../input/food-recognition-model/weights.h5'\n# model.load_weights(weights_path)","metadata":{"papermill":{"duration":2.656853,"end_time":"2021-04-29T07:10:04.192501","exception":false,"start_time":"2021-04-29T07:10:01.535648","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the defined model on the dataset\nhistory = model.fit(train_gen, steps_per_epoch=train_length//BATCH_SIZE, epochs=10)","metadata":{"_kg_hide-output":true,"papermill":{"duration":0.0329,"end_time":"2021-04-29T07:10:04.252325","exception":false,"start_time":"2021-04-29T07:10:04.219425","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to the output\nmodel.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.032493,"end_time":"2021-04-29T07:10:04.310911","exception":false,"start_time":"2021-04-29T07:10:04.278418","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test generator\nscores = model.evaluate(test_gen, steps=test_length//BATCH_SIZE)\nprint('\\nLoss: {}'.format(round(scores[0], 3)))\nprint('Average IoU: {}'.format(round(scores[1], 3)))\nprint('Average Precision: {}'.format(round(scores[2], 3)))\nprint('Average Recall: {}'.format(round(scores[3], 3)))","metadata":{"papermill":{"duration":36.520207,"end_time":"2021-04-29T07:10:40.85741","exception":false,"start_time":"2021-04-29T07:10:04.337203","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}