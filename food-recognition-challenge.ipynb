{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the pycoco library\n!pip install pycocotools","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":15.241261,"end_time":"2021-04-29T07:09:35.685421","exception":false,"start_time":"2021-04-29T07:09:20.44416","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport imgaug.augmenters as iaa","metadata":{"papermill":{"duration":0.157371,"end_time":"2021-04-29T07:09:35.860328","exception":false,"start_time":"2021-04-29T07:09:35.702957","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the image and annotation paths\ntrain_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\ntrain_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n\nval_imgs_path = '../input/food-recognition-challenge/val-v0.4/val/images'\nval_anns_path = '../input/food-recognition-challenge/val-v0.4/val/annotations.json'\n\ntest_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\ntest_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'","metadata":{"papermill":{"duration":0.021103,"end_time":"2021-04-29T07:09:35.896302","exception":false,"start_time":"2021-04-29T07:09:35.875199","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reference to Image Segmentation\n\nhttps://divamgupta.com/image-segmentation/2019/06/06/deep-learning-semantic-segmentation-keras.html","metadata":{"papermill":{"duration":0.01415,"end_time":"2021-04-29T07:09:35.924935","exception":false,"start_time":"2021-04-29T07:09:35.910785","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Function to load JSON into a COCO api\ndef getCOCO(anns_path):\n    # Initialize the COCO api for instance annotations\n    coco = COCO(anns_path)\n    \n    # Load the categories in a variable\n    catIDs = coco.getCatIds()\n    cats = coco.loadCats(catIDs)\n    \n    # Print number of categories\n    nms = [cat['name'] for cat in cats]\n    \n    # Create a dataframe of the count of each category\n    df = pd.DataFrame(columns=['Category', 'ID', 'Count'])\n    \n    # Add each category and its count row by row\n    for i, catID in enumerate(catIDs):\n        imgIds = coco.getImgIds(catIds=catID)\n        df.loc[i] = [nms[i]] + [catID] + [len(imgIds)]\n    \n    return coco, df","metadata":{"papermill":{"duration":0.022783,"end_time":"2021-04-29T07:09:35.961995","exception":false,"start_time":"2021-04-29T07:09:35.939212","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the annotations of the image dataset\ntrain_coco, train_classes = getCOCO(train_anns_path)\nval_coco, val_classes = getCOCO(val_anns_path)\ntest_coco, test_classes = getCOCO(test_anns_path)","metadata":{"_kg_hide-output":true,"papermill":{"duration":5.883051,"end_time":"2021-04-29T07:09:41.859552","exception":false,"start_time":"2021-04-29T07:09:35.976501","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAugmentation(img, mask):\n    geo_seq = iaa.Fliplr(1.0)\n    int_seq = iaa.AdditiveGaussianNoise(scale=(0, 0.2*255))\n    \n    # Apply geometric augmentations to the images and masks with a 0.5 probability\n    if random.randrange(10) % 2 == 0:\n        img_aug = geo_seq(image=img)\n        mask_aug = geo_seq(image=mask)\n    else:\n        img_aug = img\n        mask_aug = mask\n    \n    # Apply intensity augmentations to the image only\n    img_aug = int_seq(image=img_aug)\n    \n    return img_aug, mask_aug","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMask(image_id, coco, classes, image_size):\n    # Create a zero array with the given size and number of classes\n    mask = np.zeros((image_size[0], image_size[1], 274))\n\n    annIds = coco.getAnnIds(int(image_id))\n    anns = coco.loadAnns(annIds)\n\n    for i, ann in enumerate(anns):\n        # Get the binary mask for the annotation\n        binary = cv2.resize(coco.annToMask(ann), image_size)\n\n        # Get the channel index for the annotation\n        channel = classes[classes.ID == ann['category_id']].index[0] + 1\n\n        # Update the channel of the annotation\n        mask[:, :, channel] = binary\n\n        # Update the background channel of the annotation\n        if i == 0:\n            mask[:, :, 0] = np.logical_or(mask[:, :, 0], np.logical_not(binary))\n        else:\n            mask[:, :, 0] = np.logical_and(mask[:, :, 0], np.logical_not(binary))\n\n    return mask","metadata":{"papermill":{"duration":0.024192,"end_time":"2021-04-29T07:09:41.898818","exception":false,"start_time":"2021-04-29T07:09:41.874626","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getGenerator(path, coco, classes, image_size, batch_size):\n    c = 0\n    n = os.listdir(path)\n    random.shuffle(n)\n    \n    while (True):\n        img_batch = np.zeros((batch_size, image_size[0], image_size[1], 3)).astype('int')\n        mask_batch = np.zeros((batch_size, image_size[0], image_size[1], 274)).astype('float')\n\n        for i in range(c, c + batch_size):\n            img = cv2.imread(path + '/' + n[i])\n            img =  cv2.resize(img, image_size)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            mask = getMask(n[i][1:-4], coco, classes, image_size)\n            \n            img_aug, mask_aug = getAugmentation(img, mask)\n            \n            img_batch[i-c] = img_aug\n            mask_batch[i-c] = mask_aug\n\n        c += batch_size\n        if(c + batch_size >= len(os.listdir(path))):\n            c = 0\n            random.shuffle(n)\n\n        yield img_batch, mask_batch","metadata":{"papermill":{"duration":0.025692,"end_time":"2021-04-29T07:09:41.938886","exception":false,"start_time":"2021-04-29T07:09:41.913194","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the generators from the paths\nIMAGE_SIZE = (240, 240)\nBATCH_SIZE = 20\n\ntrain_gen = getGenerator(train_imgs_path, train_coco, train_classes, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntrain_length = len(os.listdir(train_imgs_path))\nprint('Number of training images: {}'.format(train_length))\n\nval_gen = getGenerator(val_imgs_path, val_coco, val_classes, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\nval_length = len(os.listdir(val_imgs_path))\nprint('Number of validation images: {}'.format(val_length))\n\ntest_gen = getGenerator(test_imgs_path, test_coco, test_classes, image_size=IMAGE_SIZE, batch_size=BATCH_SIZE)\ntest_length = len(os.listdir(test_imgs_path))\nprint('Number of test images: {}'.format(test_length))","metadata":{"papermill":{"duration":0.969098,"end_time":"2021-04-29T07:09:42.922674","exception":false,"start_time":"2021-04-29T07:09:41.953576","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualise(path, coco, classes, n):\n    temp_gen = getGenerator(path, coco, classes, image_size=IMAGE_SIZE, batch_size=n)\n    images, masks = next(temp_gen)\n    \n    for i in range(n):\n        plt.figure(figsize=(10, 20))\n        \n        plt.subplot(1, 3, 1)\n        plt.title('Image')\n        plt.imshow(images[i])\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 2)\n        plt.title('Background Channel')\n        plt.imshow(masks[i][:, :, 0])\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 3)\n        plt.title('Max of Object Channels')\n        plt.imshow(np.max(masks[i][:, :, 1:], axis=2))\n        plt.axis('off')\n        \n        plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise a few samples images with their backgrounds and objects\nvisualise(train_imgs_path, train_coco, train_classes, 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install and import the segmentation models library\n!pip install segmentation_models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","metadata":{"_kg_hide-output":true,"papermill":{"duration":13.074859,"end_time":"2021-04-29T07:09:56.013018","exception":false,"start_time":"2021-04-29T07:09:42.938159","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model to be trained\nmodel = sm.PSPNet('resnet34', encoder_weights='imagenet', encoder_freeze=True, \n                  input_shape=(48, 48, 3), downsample_factor=8, \n                  classes=274, activation='softmax')\n\nmodel.compile('Adam', loss=sm.losses.cce_dice_loss, \n              metrics=[sm.metrics.iou_score, sm.metrics.precision, sm.metrics.recall])","metadata":{"papermill":{"duration":5.475958,"end_time":"2021-04-29T07:10:01.509487","exception":false,"start_time":"2021-04-29T07:09:56.033529","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the trained model weights\n# weights_path = '../input/food-recognition-model/weights.h5'\n# model.load_weights(weights_path)","metadata":{"papermill":{"duration":2.656853,"end_time":"2021-04-29T07:10:04.192501","exception":false,"start_time":"2021-04-29T07:10:01.535648","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the defined model on the dataset\nhistory = model.fit(train_gen, steps_per_epoch=train_length//BATCH_SIZE, \n                    validation_data=val_gen, validation_steps=val_length//BATCH_SIZE, \n                    epochs=10)","metadata":{"_kg_hide-output":true,"papermill":{"duration":0.0329,"end_time":"2021-04-29T07:10:04.252325","exception":false,"start_time":"2021-04-29T07:10:04.219425","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and iou score over the epochs\nplt.figure(figsize=(20, 6))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model IoU Score')\nplt.ylabel('IoU Score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to the output\nmodel.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.032493,"end_time":"2021-04-29T07:10:04.310911","exception":false,"start_time":"2021-04-29T07:10:04.278418","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test generator\nscores = model.evaluate(test_gen, steps=test_length//BATCH_SIZE)\nprint('\\nLoss: {}'.format(round(scores[0], 3)))\nprint('Average IoU: {}'.format(round(scores[1], 3)))\nprint('Average Precision: {}'.format(round(scores[2], 3)))\nprint('Average Recall: {}'.format(round(scores[3], 3)))","metadata":{"papermill":{"duration":36.520207,"end_time":"2021-04-29T07:10:40.85741","exception":false,"start_time":"2021-04-29T07:10:04.337203","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]}]}