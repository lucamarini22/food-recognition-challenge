{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install the pycoco library\n!pip install pycocotools","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"papermill":{"duration":14.186033,"end_time":"2021-05-16T12:27:06.456587","exception":false,"start_time":"2021-05-16T12:26:52.270554","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import the necessary libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nimport cv2\nfrom pycocotools.coco import COCO\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport imgaug.augmenters as iaa","metadata":{"papermill":{"duration":1.724856,"end_time":"2021-05-16T12:27:08.200762","exception":false,"start_time":"2021-05-16T12:27:06.475906","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set important parameters\nIMAGE_SIZE = (48, 48)\nBATCH_SIZE = 300\nEPOCHS = 5","metadata":{"papermill":{"duration":0.023918,"end_time":"2021-05-16T12:27:08.242613","exception":false,"start_time":"2021-05-16T12:27:08.218695","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the image and annotation paths\ntrain_imgs_path = '../input/food-recognition-challenge/train-v0.4/train/images'\ntrain_anns_path = '../input/food-recognition-challenge/train-v0.4/train/annotations.json'\n\nval_imgs_path = '../input/food-recognition-challenge/val-v0.4/val/images'\nval_anns_path = '../input/food-recognition-challenge/val-v0.4/val/annotations.json'\n\ntest_imgs_path = '../input/food-recognition-challenge/test_images-v0.4/val/images'\ntest_anns_path = '../input/food-recognition-challenge/test_images-v0.4/val/annotations.json'","metadata":{"papermill":{"duration":0.023811,"end_time":"2021-05-16T12:27:08.284030","exception":false,"start_time":"2021-05-16T12:27:08.260219","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to load JSON into a COCO api\ndef getCOCO(anns_path):\n    # Initialize the COCO api for instance annotations\n    coco = COCO(anns_path)\n    \n    # Load the categories in a variable\n    catIDs = coco.getCatIds()\n    cats = coco.loadCats(catIDs)\n    \n    # Print number of categories\n    nms = [cat['name'] for cat in cats]\n    \n    # Create a dataframe of the count of each category\n    df = pd.DataFrame(columns=['Category', 'ID', 'Count'])\n    \n    # Add each category and its count row by row\n    for i, catID in enumerate(catIDs):\n        imgIds = coco.getImgIds(catIds=catID)\n        df.loc[i] = [nms[i]] + [catID] + [len(imgIds)]\n    \n    return coco, df","metadata":{"papermill":{"duration":0.026218,"end_time":"2021-05-16T12:27:08.327958","exception":false,"start_time":"2021-05-16T12:27:08.301740","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the annotations of the image dataset\ntrain_coco, train_classes = getCOCO(train_anns_path)\nval_coco, val_classes = getCOCO(val_anns_path)\ntest_coco, test_classes = getCOCO(test_anns_path)","metadata":{"_kg_hide-output":true,"papermill":{"duration":5.893086,"end_time":"2021-05-16T12:27:14.238429","exception":false,"start_time":"2021-05-16T12:27:08.345343","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getMask(image_id, coco, classes, image_size):\n    # Create a zero array with the given size and number of classes\n    mask = np.zeros((image_size[0], image_size[1], 274))\n\n    annIds = coco.getAnnIds(int(image_id))\n    anns = coco.loadAnns(annIds)\n\n    for i, ann in enumerate(anns):\n        # Get the binary mask for the annotation\n        binary = cv2.resize(coco.annToMask(ann), image_size, interpolation=cv2.INTER_AREA)\n\n        # Get the channel index for the annotation\n        channel = classes[classes.ID == ann['category_id']].index[0] + 1\n\n        # Update the channel of the annotation\n        mask[:, :, channel] = binary\n\n        # Update the background channel of the annotation\n        if i == 0:\n            mask[:, :, 0] = np.logical_or(mask[:, :, 0], np.logical_not(binary))\n        else:\n            mask[:, :, 0] = np.logical_and(mask[:, :, 0], np.logical_not(binary))\n\n    return mask","metadata":{"papermill":{"duration":0.028992,"end_time":"2021-05-16T12:27:14.286355","exception":false,"start_time":"2021-05-16T12:27:14.257363","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getGenerator(path, coco, classes, image_size, batch_size, augment=False):\n    c = 0\n    n = os.listdir(path)\n    random.shuffle(n)\n    \n    geo_aug = iaa.Fliplr(1.0)\n    \n    while (True):\n        img_batch = np.zeros((batch_size, image_size[0], image_size[1], 3)).astype('int')\n        mask_batch = np.zeros((batch_size, image_size[0], image_size[1], 274)).astype('float')\n\n        for i in range(c, c + batch_size):\n            img = cv2.imread(path + '/' + n[i])\n            img =  cv2.resize(img, image_size, interpolation=cv2.INTER_AREA)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            \n            mask = getMask(n[i][1:-4], coco, classes, image_size)\n            \n            if augment == True:\n                if random.random() < 0.5:\n                    img = geo_aug(image=img)\n                    mask = geo_aug(image=mask)            \n            \n            img_batch[i-c] = img\n            mask_batch[i-c] = mask\n\n        c += batch_size\n        if(c + batch_size >= len(os.listdir(path))):\n            c = 0\n            random.shuffle(n)\n\n        yield img_batch, mask_batch","metadata":{"papermill":{"duration":0.031077,"end_time":"2021-05-16T12:27:14.336128","exception":false,"start_time":"2021-05-16T12:27:14.305051","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the generators from the paths\ntrain_gen = getGenerator(train_imgs_path, train_coco, train_classes, IMAGE_SIZE, BATCH_SIZE, True)\n\ntrain_length = len(os.listdir(train_imgs_path))\nprint('Number of training images: {}'.format(train_length))\n\nval_gen = getGenerator(val_imgs_path, val_coco, val_classes, IMAGE_SIZE, BATCH_SIZE)\n\nval_length = len(os.listdir(val_imgs_path))\nprint('Number of validation images: {}'.format(val_length))\n\ntest_gen = getGenerator(test_imgs_path, test_coco, test_classes, IMAGE_SIZE, BATCH_SIZE)\n\ntest_length = len(os.listdir(test_imgs_path))\nprint('Number of test images: {}'.format(test_length))","metadata":{"papermill":{"duration":0.800883,"end_time":"2021-05-16T12:27:15.155549","exception":false,"start_time":"2021-05-16T12:27:14.354666","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualise(path, coco, classes, image_size, batch_size, augment=False):\n    temp_gen = getGenerator(path, coco, classes, image_size, batch_size, augment)\n    images, masks = next(temp_gen)\n    \n    for i in range(batch_size):\n        plt.figure(figsize=(6, 16))\n        \n        plt.subplot(1, 2, 1)\n        plt.title('Image')\n        plt.imshow(images[i])\n        plt.axis('off')\n        \n        plt.subplot(1, 2, 2)\n        plt.title('True Mask')\n        \n        true_mask = masks[i]\n        for c in range(274):\n            true_mask[:, :, c] = true_mask[:, :, c] * (c+1)\n            \n        plt.imshow(np.max(true_mask, axis=2))\n        plt.axis('off')\n        \n        plt.show()","metadata":{"papermill":{"duration":0.029148,"end_time":"2021-05-16T12:27:15.204700","exception":false,"start_time":"2021-05-16T12:27:15.175552","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise a few samples images with their backgrounds and objects\nvisualise(train_imgs_path, train_coco, train_classes, IMAGE_SIZE, 3, True)","metadata":{"papermill":{"duration":0.455413,"end_time":"2021-05-16T12:27:15.679450","exception":false,"start_time":"2021-05-16T12:27:15.224037","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install and import the segmentation models library\n!pip install segmentation_models\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm","metadata":{"_kg_hide-output":true,"papermill":{"duration":11.407488,"end_time":"2021-05-16T12:27:27.108881","exception":false,"start_time":"2021-05-16T12:27:15.701393","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the model to be trained\nmodel = sm.PSPNet('resnet152', encoder_weights='imagenet', encoder_freeze=True, \n                  input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), downsample_factor=4, \n                  classes=274, activation='softmax')\n\nmodel.compile('Adam', loss=sm.losses.cce_dice_loss, \n              metrics=[sm.metrics.iou_score, sm.metrics.precision, sm.metrics.recall])","metadata":{"papermill":{"duration":10.714924,"end_time":"2021-05-16T12:27:37.850233","exception":false,"start_time":"2021-05-16T12:27:27.135309","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Load the trained model weights\n# weights_path = '../input/food-recognition-model/weights.h5'\n# model.load_weights(weights_path)","metadata":{"papermill":{"duration":0.615468,"end_time":"2021-05-16T12:27:38.510857","exception":false,"start_time":"2021-05-16T12:27:37.895389","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the defined model on the dataset\nhistory = model.fit(train_gen, steps_per_epoch=train_length//BATCH_SIZE, \n                    validation_data=val_gen, validation_steps=val_length//BATCH_SIZE, \n                    epochs=EPOCHS)","metadata":{"_kg_hide-output":true,"papermill":{"duration":2295.863726,"end_time":"2021-05-16T13:05:54.418837","exception":false,"start_time":"2021-05-16T12:27:38.555111","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the loss and iou score over the epochs\nplt.figure(figsize=(20, 6))\nplt.subplot(121)\nplt.plot(history.history['iou_score'])\nplt.plot(history.history['val_iou_score'])\nplt.title('Model IoU Score')\nplt.ylabel('IoU Score')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(122)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","metadata":{"papermill":{"duration":0.427365,"end_time":"2021-05-16T13:05:54.993464","exception":false,"start_time":"2021-05-16T13:05:54.566099","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the model to the output\nmodel.save_weights('weights.h5')","metadata":{"papermill":{"duration":0.244495,"end_time":"2021-05-16T13:05:55.388065","exception":false,"start_time":"2021-05-16T13:05:55.143570","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model on the test generator\nscores = model.evaluate(test_gen, steps=test_length//BATCH_SIZE)\nprint('\\nLoss: {}'.format(round(scores[0], 3)))\nprint('IoU: {}'.format(round(scores[1], 3)))\nprint('Precision: {}'.format(round(scores[2], 3)))\nprint('Recall: {}'.format(round(scores[3], 3)))","metadata":{"papermill":{"duration":34.796148,"end_time":"2021-05-16T13:06:30.332173","exception":false,"start_time":"2021-05-16T13:05:55.536025","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, path, coco, classes, image_size, batch_size):\n    temp_gen = getGenerator(path, coco, classes, image_size, batch_size)\n    images, masks = next(temp_gen)\n    prediction = model.predict(images)\n    \n    for i in range(batch_size):\n        plt.figure(figsize=(10, 20))\n        \n        plt.subplot(1, 3, 1)\n        plt.title('Image')\n        plt.imshow(images[i])\n        plt.axis('off')\n        \n        plt.subplot(1, 3, 2)\n        plt.title('True Mask')\n        \n        true_mask = masks[i]\n        for c in range(274):\n            true_mask[:, :, c] = true_mask[:, :, c] * (c+1)\n            \n        plt.imshow(np.max(true_mask, axis=2))\n        plt.axis('off')\n        \n        pred_mask = np.round(prediction[i])\n        for c in range(274):\n            pred_mask[:, :, c] = pred_mask[:, :, c] * (c+1)\n            \n        plt.subplot(1, 3, 3)\n        plt.title('Predicted Mask')\n        plt.imshow(np.max(pred_mask, axis=2))\n        plt.axis('off')\n        \n        plt.show()","metadata":{"papermill":{"duration":0.161844,"end_time":"2021-05-16T13:06:30.645132","exception":false,"start_time":"2021-05-16T13:06:30.483288","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualise the predictions and the true masks\npredict(model, test_imgs_path, test_coco, test_classes, IMAGE_SIZE, 3)","metadata":{"papermill":{"duration":1.404646,"end_time":"2021-05-16T13:06:32.252254","exception":false,"start_time":"2021-05-16T13:06:30.847608","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}